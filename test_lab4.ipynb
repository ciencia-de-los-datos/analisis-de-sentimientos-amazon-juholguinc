{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dffc22ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#df = pd.read_csv(\"amazon_cells_labelled.tsv\",sep='\\t')\n",
    "with open(\"amazon_cells_labelled.tsv\", \"r\") as file:\n",
    "    data = file.read()\n",
    "\n",
    "print(type(data))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a99bcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "    df = pd.read_csv(\n",
    "        \"amazon_cells_labelled.tsv\",\n",
    "        sep='\\t',\n",
    "        encoding = 'utf-8',\n",
    "        header=None,\n",
    "        names=['msg','lbl'], \n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "468b3aa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lbl</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>13609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       msg\n",
       "lbl       \n",
       "0.0    500\n",
       "1.0    500\n",
       "NaN  13609"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"lbl\", dropna=False).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed1033da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msg</th>\n",
       "      <th>lbl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I try not to adjust the volume setting to avoi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I thought Motorola made reliable products!.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Battery for Motorola Razr.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>When I got this item it was larger than I thou...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(I looked for one that specifically said DCU-6...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14604</th>\n",
       "      <td>The screen on my phone said \"Not Charging\".</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14605</th>\n",
       "      <td>This is my 4th Samsung cell phone with T-Mobile.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14606</th>\n",
       "      <td>great company.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14607</th>\n",
       "      <td>The \"call\" and \"hang-up\" keys are now properly...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14608</th>\n",
       "      <td>Hopefully the Kyocera will be better!</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13609 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     msg  lbl\n",
       "0      I try not to adjust the volume setting to avoi...  NaN\n",
       "3            I thought Motorola made reliable products!.  NaN\n",
       "4                             Battery for Motorola Razr.  NaN\n",
       "6      When I got this item it was larger than I thou...  NaN\n",
       "7      (I looked for one that specifically said DCU-6...  NaN\n",
       "...                                                  ...  ...\n",
       "14604        The screen on my phone said \"Not Charging\".  NaN\n",
       "14605   This is my 4th Samsung cell phone with T-Mobile.  NaN\n",
       "14606                                     great company.  NaN\n",
       "14607  The \"call\" and \"hang-up\" keys are now properly...  NaN\n",
       "14608              Hopefully the Kyocera will be better!  NaN\n",
       "\n",
       "[13609 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msg</th>\n",
       "      <th>lbl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>If you are Razr owner...you must have this!</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>And the sound quality is great.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            msg  lbl\n",
       "2                   Good case, Excellent value.  1.0\n",
       "5                        Great for the jawbone.  1.0\n",
       "11                            The mic is great.  1.0\n",
       "17  If you are Razr owner...you must have this!  1.0\n",
       "24              And the sound quality is great.  1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msg</th>\n",
       "      <th>lbl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2901</th>\n",
       "      <td>The screen does get smudged easily because it ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2906</th>\n",
       "      <td>What a piece of junk.. I lose more calls on th...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2910</th>\n",
       "      <td>Item Does Not Match Picture.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2911</th>\n",
       "      <td>The only thing that disappoint me is the infra...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2913</th>\n",
       "      <td>You can not answer calls with the unit, never ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    msg  lbl\n",
       "1     So there is no way for me to plug it in here i...  0.0\n",
       "2                           Good case, Excellent value.  1.0\n",
       "5                                Great for the jawbone.  1.0\n",
       "10    Tied to charger for conversations lasting more...  0.0\n",
       "11                                    The mic is great.  1.0\n",
       "...                                                 ...  ...\n",
       "2901  The screen does get smudged easily because it ...  0.0\n",
       "2906  What a piece of junk.. I lose more calls on th...  0.0\n",
       "2910                       Item Does Not Match Picture.  0.0\n",
       "2911  The only thing that disappoint me is the infra...  0.0\n",
       "2913  You can not answer calls with the unit, never ...  0.0\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display (\n",
    "df[df['lbl'].isnull()],\n",
    "df[df['lbl'] == 1].head(5),\n",
    "df[(df['lbl'] == 1) | (df['lbl'] == 0)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3ca65e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msg</th>\n",
       "      <th>lbl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I try not to adjust the volume setting to avoi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I thought Motorola made reliable products!.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Battery for Motorola Razr.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14604</th>\n",
       "      <td>The screen on my phone said \"Not Charging\".</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14605</th>\n",
       "      <td>This is my 4th Samsung cell phone with T-Mobile.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14606</th>\n",
       "      <td>great company.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14607</th>\n",
       "      <td>The \"call\" and \"hang-up\" keys are now properly...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14608</th>\n",
       "      <td>Hopefully the Kyocera will be better!</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14609 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     msg  lbl\n",
       "0      I try not to adjust the volume setting to avoi...  NaN\n",
       "1      So there is no way for me to plug it in here i...  0.0\n",
       "2                            Good case, Excellent value.  1.0\n",
       "3            I thought Motorola made reliable products!.  NaN\n",
       "4                             Battery for Motorola Razr.  NaN\n",
       "...                                                  ...  ...\n",
       "14604        The screen on my phone said \"Not Charging\".  NaN\n",
       "14605   This is my 4th Samsung cell phone with T-Mobile.  NaN\n",
       "14606                                     great company.  NaN\n",
       "14607  The \"call\" and \"hang-up\" keys are now properly...  NaN\n",
       "14608              Hopefully the Kyocera will be better!  NaN\n",
       "\n",
       "[14609 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7205a5c",
   "metadata": {},
   "source": [
    "# pregunta1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3385730",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_tagged = df[(df['lbl'] == 1) | (df['lbl'] == 0)]\n",
    "df_untagged =df[df['lbl'].isnull()]\n",
    "x_tagged = df_tagged[\"msg\"]\n",
    "y_tagged = df_tagged[\"lbl\"]\n",
    "x_untagged = df_untagged[\"msg\"]\n",
    "y_untagged = df_untagged[\"lbl\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c146ed92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       NaN\n",
       "3       NaN\n",
       "4       NaN\n",
       "6       NaN\n",
       "7       NaN\n",
       "         ..\n",
       "14604   NaN\n",
       "14605   NaN\n",
       "14606   NaN\n",
       "14607   NaN\n",
       "14608   NaN\n",
       "Name: lbl, Length: 13609, dtype: float64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_untagged "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab80981",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47d7fba3",
   "metadata": {},
   "source": [
    "# pregunta2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04a22844",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f4232c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "        x_tagged,\n",
    "        y_tagged,\n",
    "        test_size=0.1,\n",
    "        random_state=12345,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f1ebc9e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2518a91",
   "metadata": {},
   "source": [
    "* ojo esto es explicacion de train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d7b3de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "digits = load_digits()\n",
    "\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.5,\n",
    "    shuffle=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75ac8111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40624789",
   "metadata": {},
   "source": [
    "# pregunta3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "387277bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pregunta_03():\n",
    "    \"\"\"\n",
    "    Construcción de un analizador de palabras\n",
    "    -------------------------------------------------------------------------------------\n",
    "    \"\"\"\n",
    "    # Importe el stemmer de Porter\n",
    "    # Importe CountVectorizer\n",
    "    from nltk.stem.porter import PorterStemmer\n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "    # Cree un stemeer que use el algoritmo de Porter.\n",
    "    stemmer = PorterStemmer()\n",
    "    #dfsteam = x_train.apply(lambda x: \" \".join([stemmer.stem(w) for w in x.split()]))\n",
    "\n",
    "    # Cree una instancia del analizador de palabras (build_analyzer)\n",
    "    vectorizer3 = CountVectorizer(analyzer=\"word\",token_pattern=r\"(?u)\\b[a-zA-Z][a-zA-Z]+\\b\", lowercase=True)\n",
    "    analyzer = vectorizer3.build_analyzer()\n",
    "    \n",
    "    # Retorne el analizador de palabras\n",
    "    return lambda x: (stemmer.stem(w) for w in analyzer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "bf1ecf62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['buyer',\n",
       " 'bewar',\n",
       " 'you',\n",
       " 'could',\n",
       " 'flush',\n",
       " 'money',\n",
       " 'right',\n",
       " 'down',\n",
       " 'the',\n",
       " 'toilet']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer = pregunta_03()\n",
    "result = list(\n",
    "        analyzer(\"Buyer Beware, you could flush money right down the toilet.\")\n",
    "    )\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a087ad6",
   "metadata": {},
   "source": [
    "## Analisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2f63d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9a5d778f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'buyer beware, you could flush money right down the toilet.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "256     Buyer Beware, you could flush money right down...\n",
       "2720    I was very impressed with the price of the cases.\n",
       "1856              I am more than happy with this product.\n",
       "731     I was very excited to get this headset because...\n",
       "2713                               Buttons are too small.\n",
       "                              ...                        \n",
       "1308                                   Price is good too.\n",
       "339               The BT headset was such a disapoinment.\n",
       "900                                         Great phone!.\n",
       "1474                                    A Disappointment.\n",
       "1468    After charging overnight, these batteries work...\n",
       "Name: msg, Length: 900, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "256     buyer beware, you could flush money right down...\n",
       "2720       i wa veri impress with the price of the cases.\n",
       "1856               i am more than happi with thi product.\n",
       "731     i wa veri excit to get thi headset becaus i th...\n",
       "2713                                button are too small.\n",
       "                              ...                        \n",
       "1308                                   price is good too.\n",
       "339                the bt headset wa such a disapoinment.\n",
       "900                                         great phone!.\n",
       "1474                                    a disappointment.\n",
       "1468     after charg overnight, these batteri work great.\n",
       "Name: msg, Length: 900, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "dfsteam = x_train.apply(lambda x: \" \".join([stemmer.stem(w) for w in x.split()]))\n",
    "display(\n",
    "    dfsteam.iloc[0],\n",
    "    x_train,\n",
    "    dfsteam\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "876c7581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['buyer',\n",
       " 'beware',\n",
       " 'you',\n",
       " 'could',\n",
       " 'flush',\n",
       " 'money',\n",
       " 'right',\n",
       " 'down',\n",
       " 'the',\n",
       " 'toilet']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Analizer = CountVectorizer(\n",
    "    #analyzer=\"word\",\n",
    "    lowercase=True,\n",
    "    preprocessor=None,\n",
    "    tokenizer=None,\n",
    "    #stop_words=\"english\",\n",
    "    token_pattern=r\"(?u)\\b[a-zA-Z][a-zA-Z]+\\b\",\n",
    "    #token_pattern=\"(?u)\\b\\w\\w+\\b\",\n",
    "    #binary=True,\n",
    "    binary=False,\n",
    "    max_df=1.0,\n",
    "    min_df=1,\n",
    "    #max_features=None,\n",
    "    \n",
    ")\n",
    "analyze = Analizer.build_analyzer()\n",
    "analyze(dfsteam.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3708140",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "Vocabulary not fitted or provided",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6215/1491750738.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvocabulary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAnalizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFutureWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mwrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mget_feature_names\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1427\u001b[0m             \u001b[0mA\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m         \"\"\"\n\u001b[0;32m-> 1429\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_vocabulary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mitemgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_check_vocabulary\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    496\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_vocabulary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixed_vocabulary_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Vocabulary not fitted or provided\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: Vocabulary not fitted or provided"
     ]
    }
   ],
   "source": [
    "vocabulary = Analizer.get_feature_names()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d54a6c",
   "metadata": {},
   "source": [
    "\"OJO - jememplo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9934bbf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['buyer',\n",
       " 'beware',\n",
       " 'you',\n",
       " 'could',\n",
       " 'flush',\n",
       " 'money',\n",
       " 'right',\n",
       " 'down',\n",
       " 'the',\n",
       " 'toilet']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(\n",
    "        # -------------------------------------------------------------\n",
    "        # Convert all characters to lowercase before tokenizing.\n",
    "        lowercase=True,\n",
    "        # -------------------------------------------------------------\n",
    "        # Override the preprocessing (strip_accents and lowercase)\n",
    "        # stage\n",
    "        preprocessor=None,\n",
    "        # -------------------------------------------------------------\n",
    "        # Override the string tokenization step while preserving the\n",
    "        # preprocessing and n-grams generation steps. Only applies if\n",
    "        # analyzer == 'word'.\n",
    "        tokenizer=None,\n",
    "        # -------------------------------------------------------------\n",
    "        # If ‘english’, a built-in stop word list for English is used.\n",
    "        #stop_words=\"english\",\n",
    "        # -------------------------------------------------------------\n",
    "        # Regular expression denoting what constitutes a “token”, only\n",
    "        # used if analyzer == 'word'. The default regexp select tokens\n",
    "        # of 2 or more alphanumeric characters (punctuation is\n",
    "        # completely ignored and always treated as a token separator).\n",
    "        token_pattern=r\"(?u)\\b\\w\\w+\\b\",\n",
    "        # -------------------------------------------------------------\n",
    "        # When building the vocabulary ignore terms that have a\n",
    "        # document frequency strictly higher than the given threshold\n",
    "        # (corpus-specific stop words). If float, the parameter\n",
    "        # represents a proportion of documents, integer absolute counts.\n",
    "        # This parameter is ignored if vocabulary is not None.\n",
    "        max_df=1.0,\n",
    "        # -------------------------------------------------------------\n",
    "        # When building the vocabulary ignore terms that have a\n",
    "        # document frequency strictly lower than the given threshold.\n",
    "        # This value is also called cut-off in the literature. If float,\n",
    "        # the parameter represents a proportion of documents, integer\n",
    "        # absolute counts.\n",
    "        min_df=1,\n",
    "        # -------------------------------------------------------------\n",
    "        # If not None, build a vocabulary that only consider the top\n",
    "        # max_features ordered by term frequency across the corpus.\n",
    "        max_features=None,\n",
    "        # -------------------------------------------------------------\n",
    "        # If True, all non zero counts are set to 1. This is useful for\n",
    "        # discrete probabilistic models that model binary events rather\n",
    "        # than integer counts.\n",
    "        binary=False,\n",
    "    )\n",
    "analyze1 = vectorizer.build_analyzer()\n",
    "analyze1(\"Buyer Beware, you could flush money right down the toilet. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "55d83380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['buyer',\n",
       " 'beware',\n",
       " 'you',\n",
       " 'could',\n",
       " 'flush',\n",
       " 'money',\n",
       " 'right',\n",
       " 'down',\n",
       " 'the',\n",
       " 'toilet']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer3 = CountVectorizer(analyzer=\"word\",token_pattern=r\"(?u)\\b[a-zA-Z][a-zA-Z]+\\b\")\n",
    "analyze2 = vectorizer3.build_analyzer()\n",
    "analyze2(\"Buyer Beware, you could flush money right down the toilet. \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeee9534",
   "metadata": {},
   "source": [
    "# pregunta4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e2c68190",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pregunta_04():\n",
    "    \"\"\"\n",
    "    Especificación del pipeline y entrenamiento\n",
    "    -------------------------------------------------------------------------------------\n",
    "    \"\"\"\n",
    "\n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.naive_bayes import BernoulliNB\n",
    "   \n",
    "    # Cargue las variables.\n",
    "    #x_train, x_test, y_train, y_test = pregunta_02()\n",
    "\n",
    "    # Obtenga el analizador de la pregunta 3.\n",
    "    analyzer = pregunta_03()\n",
    "\n",
    "    # Cree una instancia de CountVectorizer que use el analizador de palabras\n",
    "    # de la pregunta 3. Esta instancia debe retornar una matriz binaria. El\n",
    "    # límite superior para la frecuencia de palabras es del 100% y un límite\n",
    "    # inferior de 5 palabras. Solo deben analizarse palabras conformadas por\n",
    "    # letras.\n",
    "\n",
    "    countVectorizer = CountVectorizer(\n",
    "            analyzer=analyzer,\n",
    "            lowercase=True,\n",
    "            stop_words=\"english\",\n",
    "            token_pattern=r\"(?u)\\b[a-zA-Z][a-zA-Z]+\\b\",\n",
    "            binary=True,\n",
    "            max_df=1.0,\n",
    "            min_df=5,\n",
    "    )\n",
    "\n",
    "    #dtm = countVec.fit_transform(df.stemmed)\n",
    "\n",
    "    # Cree un pipeline que contenga el CountVectorizer y el modelo de BernoulliNB.\n",
    "    bnb = BernoulliNB()\n",
    "    pipeline = Pipeline(\n",
    "            steps=[\n",
    "                (\"countVectorizer\", countVectorizer),\n",
    "                (\"bernoulli\", bnb),\n",
    "            ],\n",
    "    )\n",
    "\n",
    "    # Defina un diccionario de parámetros para el GridSearchCV. Se deben\n",
    "    # considerar 10 valores entre 0.1 y 1.0 para el parámetro alpha de\n",
    "    # BernoulliNB.\n",
    "    dicparam = {\n",
    "            \"bernoulli__alpha\": np.arange(0.1, 1.01, 0.1),\n",
    "        }\n",
    "\n",
    "    # Defina una instancia de GridSearchCV con el pipeline y el diccionario de\n",
    "    # parámetros. Use cv = 5, y \"accuracy\" como métrica de evaluación\n",
    "    gridSearchCV = GridSearchCV(\n",
    "            estimator=pipeline,\n",
    "            param_grid=dicparam,\n",
    "            cv=5,\n",
    "            scoring=\"accuracy\",\n",
    "            refit=True,\n",
    "            return_train_score=True,\n",
    "        )\n",
    "\n",
    "    # Búsque la mejor combinación de regresores\n",
    "    gridSearchCV.fit(x_train, y_train)\n",
    "\n",
    "    # Retorne el mejor modelo\n",
    "    return gridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d5d894ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "   \n",
    "#x_train, x_test, y_train, y_test = pregunta_02()\n",
    "\n",
    "analyzer = pregunta_03()\n",
    "\n",
    "countVectorizer = CountVectorizer(\n",
    "        analyzer=analyzer,\n",
    "        lowercase=True,\n",
    "        stop_words=\"english\",\n",
    "        token_pattern=r\"(?u)\\b[a-zA-Z][a-zA-Z]+\\b\",\n",
    "        binary=True,\n",
    "        max_df=1.0,\n",
    "        min_df=5,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "dd119676",
   "metadata": {},
   "outputs": [],
   "source": [
    "bernoulliBN = BernoulliNB()\n",
    "pipeline = Pipeline(\n",
    "        steps=[\n",
    "            (\"countVectorizer\", countVectorizer),\n",
    "            (\"bernoulli\", bernoulliBN),\n",
    "        ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6665273d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "dicparam = {\n",
    "        \"bernoulli__alpha\": np.arange(0.1, 1.01, 0.1),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7d573928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bernoulli__alpha': array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ])}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicparam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ed168ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    " gridSearchCV = GridSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_grid=dicparam,\n",
    "        cv=5,\n",
    "        scoring=\"accuracy\",\n",
    "        refit=True,\n",
    "        return_train_score=True,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5c0ebbf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('countVectorizer',\n",
       "                                        CountVectorizer(analyzer=<function pregunta_03.<locals>.<lambda> at 0x7fc7a24e60d0>,\n",
       "                                                        binary=True, min_df=5,\n",
       "                                                        stop_words='english',\n",
       "                                                        token_pattern='(?u)\\\\b[a-zA-Z][a-zA-Z]+\\\\b')),\n",
       "                                       ('bernoulli', BernoulliNB())]),\n",
       "             param_grid={'bernoulli__alpha': array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ])},\n",
       "             return_train_score=True, scoring='accuracy')"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridSearchCV.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ea960aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'verbose', 'countVectorizer', 'Bernoulli', 'countVectorizer__analyzer', 'countVectorizer__binary', 'countVectorizer__decode_error', 'countVectorizer__dtype', 'countVectorizer__encoding', 'countVectorizer__input', 'countVectorizer__lowercase', 'countVectorizer__max_df', 'countVectorizer__max_features', 'countVectorizer__min_df', 'countVectorizer__ngram_range', 'countVectorizer__preprocessor', 'countVectorizer__stop_words', 'countVectorizer__strip_accents', 'countVectorizer__token_pattern', 'countVectorizer__tokenizer', 'countVectorizer__vocabulary', 'Bernoulli__alpha', 'Bernoulli__binarize', 'Bernoulli__class_prior', 'Bernoulli__fit_prior'])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridSearchCV.estimator.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "97eeffc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7822222222222223"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridSearchCV.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b9f70a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              bernoulli__alpha: 0.1\n"
     ]
    }
   ],
   "source": [
    "best_parameters = gridSearchCV.best_estimator_.get_params()\n",
    "for param_name in sorted(dicparam):\n",
    "    print(\"{:>30s}: {:s}\".format(param_name, repr(best_parameters[param_name])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e05b0acc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8766666666666667"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridSearchCV.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "adcd0414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridSearchCV.score(x_test, y_test).round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cbdd85",
   "metadata": {},
   "source": [
    "# Pregunta 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3831a4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pregunta_05():\n",
    "    \"\"\"\n",
    "    Evaluación del modelo\n",
    "    -------------------------------------------------------------------------------------\n",
    "    \"\"\"\n",
    "\n",
    "    # Importe confusion_matrix\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "\n",
    "    # Obtenga el pipeline de la pregunta 3.\n",
    "    gridSearchCV = pregunta_04()\n",
    "\n",
    "    # Cargue las variables.\n",
    "    x_train, x_test, y_train, y_test = pregunta_02()\n",
    "\n",
    "    # Evalúe el pipeline con los datos de entrenamiento usando la matriz de confusion.\n",
    "    cfm_train = confusion_matrix(\n",
    "        y_true=y_train,\n",
    "        y_pred=gridSearchCV.predict(x_train),\n",
    "    )\n",
    "\n",
    "    cfm_test = confusion_matrix(\n",
    "        y_true=y_test,\n",
    "        y_pred=gridSearchCV.predict(x_test),\n",
    "    )\n",
    "\n",
    "    # Retorne la matriz de confusion de entrenamiento y prueba\n",
    "    return cfm_train, cfm_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4e7ba1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "gridSearchCV = pregunta_04()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "267b84aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256     0.0\n",
       "2720    1.0\n",
       "1856    1.0\n",
       "731     1.0\n",
       "2713    0.0\n",
       "       ... \n",
       "1308    1.0\n",
       "339     0.0\n",
       "900     1.0\n",
       "1474    0.0\n",
       "1468    1.0\n",
       "Name: lbl, Length: 900, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0.,\n",
       "       0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1.,\n",
       "       1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1.,\n",
       "       0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0.,\n",
       "       0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,\n",
       "       0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1.,\n",
       "       1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
       "       1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1.,\n",
       "       0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0.,\n",
       "       0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0.,\n",
       "       1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0.,\n",
       "       1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "       1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
       "       1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,\n",
       "       1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1.,\n",
       "       0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1.,\n",
       "       0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0.,\n",
       "       1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0.,\n",
       "       1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1.,\n",
       "       1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0.,\n",
       "       0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1.,\n",
       "       1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
       "       1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,\n",
       "       1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
       "       1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1.,\n",
       "       1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "       1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "       1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1.,\n",
       "       1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1.,\n",
       "       0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "       1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "       0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1.,\n",
       "       0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1.,\n",
       "       0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0.,\n",
       "       0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0.,\n",
       "       1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1.,\n",
       "       0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1.,\n",
       "       1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1.,\n",
       "       1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1.,\n",
       "       1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1.,\n",
       "       0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1.,\n",
       "       1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1.,\n",
       "       0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "       1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1.])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(\n",
    "    y_train,\n",
    "    gridSearchCV.predict(x_train),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1affa9",
   "metadata": {},
   "source": [
    "# Pregunta 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "655baf58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[394,  60],\n",
       "       [ 51, 395]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfm_train = confusion_matrix(\n",
    "    y_true=y_train,\n",
    "    y_pred=gridSearchCV.predict(x_train),\n",
    "    )\n",
    "cfm_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6dd36c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "402     0.0\n",
       "2386    0.0\n",
       "835     0.0\n",
       "1424    0.0\n",
       "2722    1.0\n",
       "       ... \n",
       "2080    1.0\n",
       "2269    1.0\n",
       "1790    1.0\n",
       "270     0.0\n",
       "2222    1.0\n",
       "Name: lbl, Length: 100, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,\n",
       "       1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0.,\n",
       "       1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0.,\n",
       "       1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
       "       0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1.])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[32, 14],\n",
       "       [ 9, 45]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cfm_test = confusion_matrix(\n",
    "        y_true=y_test,\n",
    "        y_pred=gridSearchCV.predict(x_test),\n",
    "    )\n",
    "display(\n",
    "    y_test,\n",
    "    gridSearchCV.predict(x_test),\n",
    "    cfm_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8a4cbc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "gridSearchCV = pregunta_04()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e06ee25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_untagged_pred = gridSearchCV.predict(x_untagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "817f148d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13609,)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_untagged_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "1bc6acc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., ..., 1., 0., 0.])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_untagged_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "412b5e98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_untagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "5b2db7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_59344/3609501534.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_untagged['y_untagged_pred']=y_untagged_pred\n"
     ]
    }
   ],
   "source": [
    "df_untagged['y_untagged_pred']=y_untagged_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "033d187d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msg</th>\n",
       "      <th>lbl</th>\n",
       "      <th>y_untagged_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I try not to adjust the volume setting to avoi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I thought Motorola made reliable products!.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Battery for Motorola Razr.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>When I got this item it was larger than I thou...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(I looked for one that specifically said DCU-6...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14604</th>\n",
       "      <td>The screen on my phone said \"Not Charging\".</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14605</th>\n",
       "      <td>This is my 4th Samsung cell phone with T-Mobile.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14606</th>\n",
       "      <td>great company.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14607</th>\n",
       "      <td>The \"call\" and \"hang-up\" keys are now properly...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14608</th>\n",
       "      <td>Hopefully the Kyocera will be better!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13609 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     msg  lbl  y_untagged_pred\n",
       "0      I try not to adjust the volume setting to avoi...  NaN              0.0\n",
       "3            I thought Motorola made reliable products!.  NaN              1.0\n",
       "4                             Battery for Motorola Razr.  NaN              1.0\n",
       "6      When I got this item it was larger than I thou...  NaN              1.0\n",
       "7      (I looked for one that specifically said DCU-6...  NaN              1.0\n",
       "...                                                  ...  ...              ...\n",
       "14604        The screen on my phone said \"Not Charging\".  NaN              0.0\n",
       "14605   This is my 4th Samsung cell phone with T-Mobile.  NaN              1.0\n",
       "14606                                     great company.  NaN              1.0\n",
       "14607  The \"call\" and \"hang-up\" keys are now properly...  NaN              0.0\n",
       "14608              Hopefully the Kyocera will be better!  NaN              0.0\n",
       "\n",
       "[13609 rows x 3 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_untagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "da87c42a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 1.])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array(['the worst item i ever bought', 'i love it','think twice before buy it','great product'])\n",
    "  \n",
    "ser = pd.Series(data)\n",
    "pred = gridSearchCV.predict(ser)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c089cbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(['g', 'e', 'e', 'k', 's'])\n",
    "  \n",
    "ser = pd.Series(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
